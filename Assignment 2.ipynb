{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name:\n",
    "#### Student ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 190 Assignment 2\n",
    "\n",
    "### Hidden Markov Model, LZify, and Speech Formants with Linear Predictive Coding\n",
    "\n",
    "Instructions: \n",
    "\n",
    "* This notebook is an interactive assignment; please read and follow the instructions in each cell. \n",
    "\n",
    "* Cells that require your input (in the form of code or written response) will have 'Question #' above.\n",
    "\n",
    "* After completing the assignment, please submit this notebook as a PDF and a WAV file of your Fur Elise variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM-Based Chord Recognition\n",
    "\n",
    "In music, certain chord transitions are more likely than others. This idea can be applied as Hidden Markov Models, where the first-order temporal relationships between the various chords are captured by the transition probability matrix $A$. \n",
    "\n",
    "If we consider only major and minor chords, there are a total of 24 chords in this model (12 major, from C through B, and 12 minor, from C through B), formalized as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:ChordReco:HMM:App:Spec:SetStates}\n",
    "  \\mathcal{A} = \\{\\mathbf{C},\\mathbf{C}^\\sharp,\\ldots,\\mathbf{B},\\mathbf{Cm},\\mathbf{Cm^\\sharp},\\ldots,\\mathbf{Bm}\\} \n",
    "\\end{equation}\n",
    "\n",
    "We use the notation $\\alpha{i}\\rightarrow\\alpha{j}$ referring to the transition from state $\\alpha{i}$ to state $\\alpha{j}$, $i,j\\in[1:24]$. For example, the coefficient $a_{1,2}$ expresses the \n",
    "probability for the transition $\\alpha_{1}\\rightarrow\\alpha_{2}$ (corresponding to  $\\mathbf{C}\\rightarrow\\mathbf{C}^\\sharp$), whereas $a_{1,8}$ expresses the probability for $\\alpha_{1}\\rightarrow\\alpha_{8}$  (corresponding to  $\\mathbf{C}\\rightarrow\\mathbf{G}$). In real music, the change from a tonic to the dominant is much more likely\n",
    "than transposing by one semitone, so that the probability $a_{1,8}$ should be much larger than $a_{1,2}$. The coefficients $a_{i,i}$ express the probability of staying in state $\\alpha_{i}$ (i.e., $\\alpha_{i}\\rightarrow\\alpha_{i}$), $i\\in[1:24]$. These coefficients are also referred to as **self-transition** probabilities.\n",
    "\n",
    "A transition probability matrix can be specified in many ways. For example, the matrix may be defined manually by a music expert based on rules from harmony theory. The most common approach is to generate such a matrix automatically \n",
    "by estimating the transition probabilities from labeled data. \n",
    "\n",
    "In the following exercise, you will train an HMM on transition probabilities found in the music of the Beatles using bigrams (pairs of adjacent elements) in labeled frame sequences from a subset of the Beatles Corpus.\n",
    "\n",
    "For this assignment, assume each row in the dataset represents a chord that has followed the chord on the previous row in a Beatles song. When parsing the file for your model, you may discard any chord references beyond key and major/minor quality. For example, if a row reads 'Bbm7', you would parse for the key (B-flat) and quality (minor), but discard the extra information that it is a 7th chord.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from numpy.random import multinomial as randm\n",
    "from numpy import where\n",
    "import scipy.signal as si\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import scipy\n",
    "from matplotlib import patches\n",
    "import librosa.display as ld\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "data = pd.read_csv('data/Liverpool_band_chord_sequence.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1\n",
    "\n",
    "Using the above data, generate a 24x24 matrix, where each matrix element (i,j) is the transition probability from chord i to chord j. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMM = np.zeros((24,24))\n",
    "\n",
    "### Your code here: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transition_matrix(A, ax=None, xlabel='State $a_j$', ylabel='State $a_i$', title='', clim=[-6, 0], cmap='gray_r'):\n",
    "    \n",
    "    im = ax[0].imshow(A, origin='lower', aspect='auto', cmap=cmap)\n",
    "    im.set_clim([-6, 0])\n",
    "    plt.sca(ax[0])\n",
    "    cbar = plt.colorbar(im)\n",
    "    ax[0].set_xlabel(xlabel)\n",
    "    ax[0].set_ylabel(ylabel)\n",
    "    ax[0].set_title(title)\n",
    "    cbar.ax.set_ylabel('Probability')\n",
    "    \n",
    "    chroma_label = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    chord_label_maj = chroma_label\n",
    "    chord_label_min = [s + 'm' for s in chroma_label]\n",
    "    chord_labels = chord_label_maj + chord_label_min\n",
    "    chord_labels_squeezed = chord_labels.copy()\n",
    "    for k in [13, 15, 17, 18, 20, 22]:\n",
    "        chord_labels_squeezed[k] = ''\n",
    "        \n",
    "    ax[0].set_xticks(np.arange(24))\n",
    "    ax[0].set_yticks(np.arange(24))\n",
    "    ax[0].set_xticklabels(chord_labels_squeezed)\n",
    "    ax[0].set_yticklabels(chord_labels)\n",
    "    \n",
    "    return im\n",
    "\n",
    "plot_transition_matrix(HMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2\n",
    "\n",
    "Using your HMM, you will create your own 16-measure Beatles hits!\n",
    "For your first song, beginning on C major, select each next chord by choosing the chord with the largest transition probability from the current chord:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_beatles_hit = ''\n",
    "\n",
    "### Your code here:\n",
    "\n",
    "\n",
    "print(my_first_beatles_hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3\n",
    "\n",
    "For your second song, beginning on C major, select each next chord at random according to the probabilities of your HMM.\n",
    "For example, if C major transitions to G major with probability .5, F major with probability .25, and D minor with probability .25, then your next chord should be selected randomly from (G, F, Dm) with probability of selection (.5, .25, .25) respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_second_beatles_hit = ''\n",
    "\n",
    "### Your code here:\n",
    "\n",
    "\n",
    "print(my_second_beatles_hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LZify: Applying Universal Prediction to Musical Style\n",
    "\n",
    "In this section, you will implement the Incremental Parsing (IP) from the LZ78 method for creating a dictionary of motifs. These motifs are later used to generate new sequences resembling the input sequence.\n",
    "\n",
    "Please read the algorithm in Assayag, Dubnov, and Delerue's \"Guessing the Composerâ€™s Mind\" (available at https://pdfs.semanticscholar.org/0181/236e1b417c8dd5dddd1f919583893f7a9026.pdf). \n",
    "\n",
    "The IPMotif function should compute the motif dictionary discovered in the text. It uses Incremental Parsing method to parse the text into unseen motifs.\n",
    "\n",
    "##### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPMotif(text):\n",
    "    \"\"\"Compute an associative dictionary (the motif dictionary).\"\"\"\n",
    "    \n",
    "    dictionary = {}\n",
    "    \n",
    "    ### Your Code Here:\n",
    "\n",
    "    \n",
    "    \n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text below contains an excerpt of Beethoven's Fur Elise, written as MML (Music Macro Language). MML is used to represent musical melodies as text. \n",
    "\n",
    "You can read more about MML syntax here: https://en.wikipedia.org/wiki/Music_Macro_Language\n",
    "\n",
    "You can play with MML in this webapp: http://benjaminsoule.fr/tools/vmml/\n",
    "\n",
    "Try playing the text below in the webapp to hear sample output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'o6ed+ed+ec-dc>aceabeg+bb+e<ed+ed+ec-dc>aceabe<c>bab<cde>g<fed>f<edc>e<dc>be<eeed+ed+ec-dc>aceabeg+bb+e<ed+ed+ec-dc>aceabe<c>ba'\n",
    "dict1 = IPMotif(text)\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement the IPContinuation and Normalize functions. \n",
    "The IPContinuation function transforms the IPMotif dictionary into a tree-like representation to allow finding continuations for new  motifs. The Normalize function turns the counters in every element of the IPContinuation dictionary into probabilities. \n",
    "\n",
    "##### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPContinuation(dict1):\n",
    "    \"\"\"Compute continuation dictionary from a motif dictionary\"\"\"\n",
    "    \n",
    "    dict2 = {}\n",
    "\n",
    "    ### Your Code Here: \n",
    "    \n",
    "    \n",
    "    return dict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(dict2):\n",
    "    \"\"\"Turns the counters in every element of dict2 to probabilities\"\"\"\n",
    "\n",
    "    ### Your Code Here:\n",
    "    \n",
    "\n",
    "    return dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2 = IPContinuation(dict1)\n",
    "print(dict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generting a new sequence is done by traversing the IPContinuation tree and selecting possible branches according to their weights. If motif is not found, its last symbol is removed and the process is repeated for a shorter motif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPGenerate(n,dict2):\n",
    "    p = 0\n",
    "    out = \"\"\n",
    "    for k in range(n):\n",
    "        while True:\n",
    "            context = out[-p:]\n",
    "            if context in dict2:\n",
    "                prob = [tup[1] for tup in dict2[context]]\n",
    "                conti = where(randm(1,prob))[0][0]\n",
    "                cont = dict2[context][conti][0]\n",
    "                out = out + cont\n",
    "                break\n",
    "            else:\n",
    "                p = p-1\n",
    "    return out\n",
    "out = IPGenerate(92,dict2)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 7\n",
    "\n",
    "Paste your output in the online MML player, and listen to your piece. Do you hear elements of Fur Elise in your composition? What are some of the differences in the output from the original? \n",
    "\n",
    "Please export the WAV file of your output from the webapp, and submit the WAV file with your assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few important points:\n",
    "1. The method captures the \"texture\" of the language but not it's meaning.\n",
    "2. We could parse a new text using IPMotifs from two languages, then count the length and number of motifs in order to decide what was the language of the new text.\n",
    "3. In order to use this method with musical information, we need first to translate audio to features, or in case of polyphonic midi change this into some proper representation. One possibility is using virtual fundamental or chroma for harmony, or some other specialized representation to capture repetition in terms of other specific musical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Formants and LPC\n",
    "\n",
    "In this section, you will synthesize vowel sounds, and investigate the frequencies in vowels from your own voice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fdict = {\n",
    "    'mystery_1':[[328, 2208, 2885],[27,80,575]],\n",
    "    'mystery_2':[[504, 868, 2654],[62,   108,  299]],\n",
    "    'mystery_3':[[700, 1220, 2600],[130,   70,  160]]\n",
    "    } # Formant frequencies in Hz\n",
    "\n",
    "def excitation(f0,jitt,dur,nharm=None,unvoiced=False):\n",
    "    w0T = 2*np.pi*f0/fs\n",
    "\n",
    "    if nharm == None:\n",
    "        nharm = int((fs/2)/f0) # number of harmonics\n",
    "    nsamps = fs*dur\n",
    "    sig = np.zeros(nsamps)\n",
    "    ph = np.random.uniform(size=nsamps)*2*np.pi\n",
    "    n = np.arange(nsamps)\n",
    "\n",
    "    if unvoiced:\n",
    "        sig = np.random.normal(size=nsamps)\n",
    "    else:\n",
    "    # Synthesize bandlimited impulse train\n",
    "        for i in range(1,nharm):\n",
    "            sig = sig + np.cos(i*w0T*n + jitt*ph)\n",
    "    \n",
    "    sig = sig/max(sig)\n",
    "    return sig\n",
    "\n",
    "def voca(sig,F,Fb):\n",
    "    R = np.exp(-np.pi*Fb/fs);     # Pole radii\n",
    "    theta = 2*np.pi*F/fs;     # Pole angles\n",
    "    poles = R * np.exp(1j*theta) # Poles[B,A] = zpk2tf(0,np.concatenate((poles, np.conj(poles))),1) # Filter from zeros and poles\n",
    "    \n",
    "    [B,A] = si.zpk2tf(0,np.concatenate((poles, np.conj(poles))),1) # Filter from zeros and poles\n",
    "\n",
    "    speech = si.lfilter(B, A, sig)\n",
    "    speech = speech/np.std(speech)\n",
    "    return speech,B,A\n",
    "\n",
    "def J(x):\n",
    "    x = (x - np.mean(x))/np.std(x)\n",
    "    kurt = np.mean(np.power(x,4)) - 3*np.power(np.mean(np.power(x,2)),2)\n",
    "    return 1./12*np.power(np.mean(np.power(x,3)),2) + 1./48*kurt\n",
    "\n",
    "fs = 8192 # 22050  % Sampling rate in Hz (\"telephone quality\" for speed)\n",
    "\n",
    "vowels = list(Fdict.keys())\n",
    "f0 = 150 # Pitch in Hz\n",
    "dur = 1 #one second in duration\n",
    "ji = 0.1 #0.1\n",
    "ex = excitation(f0,ji,dur)\n",
    "\n",
    "text = ['mystery_1','mystery_2','mystery_3']\n",
    "\n",
    "speech = np.zeros(1)\n",
    "for t in text:\n",
    "    F = np.array(Fdict[t][0])\n",
    "    Fb = np.array(Fdict[t][1])\n",
    "    print(t)\n",
    "\n",
    "    vow,B,A = voca(ex,F,Fb)\n",
    "    speech = np.concatenate((speech,vow))\n",
    "\n",
    "speech = speech/np.std(speech)\n",
    "plt.plot(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(speech, rate=fs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 8\n",
    "\n",
    "Based on the audio output, what vowels were synthesized as mystery_1, mystery_2, and mystery_3? \n",
    "Please specify using a word; for example, if you heard an 'oo' sound as in 'hoot', you may answer with the word \"hoot\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mystery_1:\n",
    "\n",
    "mystery_2:\n",
    "\n",
    "mystery_3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will examine just one vowel in greater detail. \n",
    "Select one mystery vowel to analyze below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "### Modify the line below:\n",
    "text = ['SELECT_ONE_MSYERY_VOWEL']\n",
    "\n",
    "speech = np.zeros(1)\n",
    "for t in text:\n",
    "    F = np.array(Fdict[t][0])\n",
    "    Fb = np.array(Fdict[t][1])\n",
    "    print(t)\n",
    "\n",
    "    vow,B,A = voca(ex,F,Fb)\n",
    "    speech = np.concatenate((speech,vow))\n",
    "\n",
    "speech = speech/np.std(speech)\n",
    "plt.plot(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.psd(speech, 1024)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_order = 10\n",
    "s = speech\n",
    "\n",
    "a = librosa.core.lpc(s, lpc_order)\n",
    "print(a)\n",
    "s_hat = scipy.signal.lfilter([0] + -1*a[1:], [1], s)\n",
    "s_err = s[1:] - s_hat[:-1]\n",
    "plt.plot(s[1:])\n",
    "plt.plot(s_hat[:-1], linestyle='--')\n",
    "plt.legend(['y', 'y_hat'])\n",
    "plt.title('LP Model Forward Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s[1:101])\n",
    "plt.plot(s_hat[:100])\n",
    "plt.legend(['y', 'y_hat'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 9\n",
    "\n",
    "What is being visualized as y and y_hat on the above plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h = si.freqz(b=1,a = a, fs=1)\n",
    "plt.plot(w,20*np.log10(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z,p,k = si.tf2zpk(B,A)\n",
    "    \n",
    "unit_circle = patches.Circle((0,0), radius=1, fill=False, color='black', ls='solid', alpha=0.9)\n",
    "ax = plt.subplot(111)\n",
    "ax.add_patch(unit_circle)\n",
    "ax.spines['left'].set_position('center')\n",
    "ax.spines['bottom'].set_position('center')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "r = 1.5; plt.axis('scaled'); plt.axis([-r, r, -r, r])\n",
    "ticks = [-1, -.5, .5, 1]; plt.xticks(ticks); plt.yticks(ticks)    \n",
    "    \n",
    "plt.plot(z.real, z.imag, 'ko', fillstyle='none', ms = 10)\n",
    "plt.plot(p.real, p.imag, 'kx', fillstyle='none', ms = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.abs(librosa.stft(s,n_fft=256,hop_length = 64))\n",
    "ld.specshow(librosa.amplitude_to_db(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 10\n",
    "\n",
    "Record yourself speaking the same vowel sound you analyzed above. \n",
    "Graph the power spectral density of your recording alongside the LPC spectrum generated above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 11\n",
    "\n",
    "How does the power spectral density of your recorded signal compare to the LPC spectrum? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
